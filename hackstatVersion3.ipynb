{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackstatVersion3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6mjVEfZHrFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries for building the neural network\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold,cross_val_score,RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bt9g_J9H2Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the data\n",
        "data = pd.read_csv(io.BytesIO(uploaded['Trainset.csv'])).dropna()\n",
        "test = pd.read_csv(io.BytesIO(uploaded['xtest.csv'])).dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4d2puU9H5Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# break the data and remove unnecessary colums\n",
        "\n",
        "prediction_var = ['Homepage','Homepage _Duration', 'Aboutus', 'Aboutus_Duration', 'Contactus', 'Contactus_Duration',\n",
        "           'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems',\n",
        "           'Browser', 'Province', 'TrafficType','VisitorType','Weekend']\n",
        "\n",
        "X = data[prediction_var]\n",
        "Y = data.Revenue\n",
        "test_id= test['ID']\n",
        "del test['ID']\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMReJmKWH6AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the data\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(X['Month'])\n",
        "(X['Month']) = encoder.transform(X['Month'])\n",
        "encoder.fit(X['Weekend'])\n",
        "(X['Weekend']) = encoder.transform(X['Weekend'])\n",
        "encoder.fit(X['VisitorType'])\n",
        "(X['VisitorType']) = encoder.transform(X['VisitorType'])\n",
        "\n",
        "\n",
        "encoder.fit(test['Month'])\n",
        "(test['Month']) = encoder.transform(test['Month'])\n",
        "encoder.fit(test['Weekend'])\n",
        "(test['Weekend']) = encoder.transform(test['Weekend'])\n",
        "encoder.fit(test['VisitorType'])\n",
        "(test['VisitorType']) = encoder.transform(test['VisitorType'])\n",
        "\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ_YjSECIAj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converted all the columns to float\n",
        "X=X.astype(float)\n",
        "test=test.astype(float)\n",
        "Y=Y.astype(float)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-WD6Xu9IBiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardized the data\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "test = sc.fit_transform(test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4bUttSmIEIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# break the training data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=66)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWXp1g1ISgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier(n_estimators=600,  max_features='sqrt',max_depth: 380)\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "# predictions\n",
        "rfc_predict = rfc.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ao-4GC8IWfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "rfc_cv_score = cross_val_score(rfc, X, Y, cv=10, scoring='roc_auc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHNkzSbgIfxs",
        "colab_type": "code",
        "outputId": "336998a3-be94-4fc8-daf9-4635bc694307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, rfc_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, rfc_predict))\n",
        "print('\\n')\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[2792  128]\n",
            " [ 211  323]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94      2920\n",
            "         1.0       0.72      0.60      0.66       534\n",
            "\n",
            "    accuracy                           0.90      3454\n",
            "   macro avg       0.82      0.78      0.80      3454\n",
            "weighted avg       0.90      0.90      0.90      3454\n",
            "\n",
            "\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.93665384 0.92078611 0.92928437 0.9300272  0.92825122 0.90715253\n",
            " 0.93242696 0.93604408 0.92574088 0.93695883]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Random Forest:  0.9283326014591932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mascf-0eNFJz",
        "colab_type": "code",
        "outputId": "106adefc-6bae-406f-89b5-114f11004287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Tuning Hyperparameters\n",
        "\n",
        "# number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# number of features at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# max depth\n",
        "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]\n",
        "max_depth.append(None)\n",
        "# create random grid\n",
        "random_grid = {\n",
        " 'n_estimators': n_estimators,\n",
        " 'max_features': max_features,\n",
        " 'max_depth': max_depth\n",
        " }\n",
        "# Random search of parameters\n",
        "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
        "# Fit the model\n",
        "rfc_random.fit(X_train, y_train)\n",
        "# print results\n",
        "print(rfc_random.best_params_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 17.4min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 25.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 380}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9JIuX0kBIil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting the test values and downloading the csv file\n",
        "Y_test= (rfc.predict(test)>0.5)\n",
        "ID = pd.DataFrame(test_id, columns = ['ID']) \n",
        "REV = pd.DataFrame(Y_test, columns = ['Revenue']) \n",
        "COLS = [ID,REV]\n",
        "result = pd.concat(COLS, axis=1)\n",
        "\n",
        "encoder.fit(result['Revenue'])\n",
        "(result['Revenue']) = encoder.transform(result['Revenue'])\n",
        "result.columns\n",
        "result.to_csv('result.csv') \n",
        "files.download(\"result.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}